_BASE_: ./oneformer_R50_bs16_160k.yaml
MODEL:
  BACKBONE:
    NAME: "D2ConvNeXt"
  CONVNEXT:
    IN_CHANNELS: 3
    DEPTHS: [3, 3, 27, 3]
    DIMS: [192, 384, 768, 1536]
    DROP_PATH_RATE: 0.4
    LSIT: 1.0
    OUT_INDICES: [0, 1, 2, 3]
  WEIGHTS: "./checkpoints/convnext_large_22k_1k_384.pkl"
  PIXEL_MEAN: [123.95182413470533, 106.21117867165576, 90.16592609915809]
  PIXEL_STD: [56.69305425631431, 56.69305425631431, 56.69305425631431]
  ONE_FORMER:
    NUM_OBJECT_QUERIES: 18
INPUT:
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 21)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 2560
  MAX_SIZE_TEST: 2560
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)
    SINGLE_CATEGORY_MAX_AREA: 1.0
  COLOR_AUG_SSD: True
  SIZE_DIVISIBILITY: 640  # used in dataset mapper
  FORMAT: "RGB"
TEST:
  DETECTIONS_PER_IMAGE: 13
  EVAL_PERIOD: 2000
  AUG:
    ENABLED: False
    MIN_SIZES: [320, 480, 640, 800, 960, 1120]
    MAX_SIZE: 4480
    FLIP: True
